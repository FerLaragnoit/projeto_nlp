"""
app.py

Aplica√ß√£o Streamlit para resumo e simplifica√ß√£o de textos.
Interface web interativa que permite processar textos usando NLP e modelos de linguagem.
"""

import streamlit as st
import numpy as np
from typing import Dict, List
import io

# Importa os m√≥dulos personalizados
import nlp_pipeline
import llm_client


# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Vozes acess√≠veis",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)


# Estilos CSS personalizados (paleta verde claro e cinza)
st.markdown("""
<style>
    /* Cabe√ßalhos principais em verde */
    h1, h2, h3 {
        color: #2d6a4f;
    }
    
    /* Bot√µes em verde */
    .stButton>button {
        background-color: #52b788;
        color: white;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: bold;
    }
    
    .stButton>button:hover {
        background-color: #40916c;
    }
    
    /* Caixas de destaque */
    .stAlert {
        background-color: #3D8737;
        border-left: 4px solid #52b788;
    }
    
    /* Sidebar em tons de cinza claro */
    .css-1d391kg {
        background-color: #f8f9fa;
    }
    
    /* M√©tricas */
    .stMetric {
        background-color: #e9ecef;
        padding: 1rem;
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)


def extrair_texto_de_arquivo(arquivo) -> str:
    """
    Extrai texto de arquivo enviado pelo usu√°rio (.txt ou .pdf).
    
    Args:
        arquivo: Objeto de arquivo do Streamlit
        
    Returns:
        Texto extra√≠do do arquivo
    """
    nome_arquivo = arquivo.name.lower()
    
    try:
        if nome_arquivo.endswith('.txt'):
            # L√™ arquivo de texto simples
            texto = arquivo.read().decode('utf-8', errors='ignore')
            return texto
            
        elif nome_arquivo.endswith('.pdf'):
            # Tenta importar biblioteca para PDF
            try:
                import PyPDF2
                
                # L√™ o PDF
                leitor_pdf = PyPDF2.PdfReader(io.BytesIO(arquivo.read()))
                texto_completo = ""
                
                for pagina in leitor_pdf.pages:
                    texto_completo += pagina.extract_text() + "\n"
                
                return texto_completo
                
            except ImportError:
                st.error("Biblioteca PyPDF2 n√£o est√° instalada. Execute: pip install PyPDF2")
                return ""
                
        else:
            st.error("Formato de arquivo n√£o suportado. Use .txt ou .pdf")
            return ""
            
    except Exception as e:
        st.error(f"Erro ao ler arquivo: {str(e)}")
        return ""


def exibir_detalhes_nlp(chunks: List[Dict], chunks_selecionados: List[Dict], 
                        embeddings_info: Dict):
    """
    Exibe detalhes t√©cnicos do processamento de NLP.
    
    Args:
        chunks: Lista completa de chunks
        chunks_selecionados: Lista de chunks selecionados
        embeddings_info: Informa√ß√µes sobre os embeddings calculados
    """
    st.subheader("Detalhes do Processamento de NLP")
    
    # Informa√ß√µes sobre chunks
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Total de chunks gerados", len(chunks))
        st.metric("Chunks selecionados", len(chunks_selecionados))
    
    with col2:
        percentual = (len(chunks_selecionados) / len(chunks) * 100) if chunks else 0
        st.metric("Percentual selecionado", f"{percentual:.1f}%")
        st.metric("Dimens√£o dos embeddings", embeddings_info.get('dimensao', 'N/A'))
    
    # Informa√ß√µes sobre embeddings
    st.write("**Informa√ß√µes de Embeddings:**")
    st.write(f"- Modelo usado: {embeddings_info.get('modelo', 'N/A')}")
    st.write(f"- N√∫mero de embeddings calculados: {embeddings_info.get('num_embeddings', 0)}")
    
    # Mostra trechos dos chunks selecionados
    st.write("**Chunks selecionados (pr√©via):**")
    
    for chunk in chunks_selecionados[:5]:  # Mostra no m√°ximo 5
        with st.expander(f"Chunk {chunk['indice']} - Similaridade: {chunk.get('similaridade', 0):.3f}"):
            # Mostra apenas as primeiras 300 caracteres
            trecho = chunk['texto'][:300]
            if len(chunk['texto']) > 300:
                trecho += "..."
            st.text(trecho)
            st.caption(f"Tamanho: {chunk['tamanho']} caracteres | Palavras: {chunk['num_palavras']}")


def processar_texto(texto_entrada: str, tipo_saida: str, tamanho_resumo: str,
                   mostrar_detalhes: bool) -> Dict:
    """
    Executa o pipeline completo de processamento do texto.
    
    Args:
        texto_entrada: Texto fornecido pelo usu√°rio
        tipo_saida: "Resumo" ou "Versao simplificada"
        tamanho_resumo: "Curto", "Medio" ou "Longo"
        mostrar_detalhes: Se deve retornar detalhes t√©cnicos
        
    Returns:
        Dicion√°rio com resultados do processamento
    """
    resultado = {
        'sucesso': False,
        'texto_gerado': "",
        'estatisticas_entrada': {},
        'estatisticas_saida': {},
        'chunks': [],
        'chunks_selecionados': [],
        'embeddings_info': {},
        'erro': None
    }
    
    try:
        # Etapa 1: Pr√©-processamento
        with st.spinner("Processando texto (limpeza e segmenta√ß√£o)..."):
            # Usa chunks menores (500 chars) para evitar problemas com limite de tokens
            texto_limpo, chunks, estatisticas = nlp_pipeline.processar_texto_completo(
                texto_entrada,
                percentual_selecao=0.7,
                tamanho_chunk=500  # Reduzido para 500 caracteres por chunk
            )
            
            resultado['estatisticas_entrada'] = estatisticas
            resultado['chunks'] = chunks
        
        # Etapa 2: Embeddings
        with st.spinner("Calculando embeddings..."):
            # Gera embedding do documento completo
            embedding_global = llm_client.gerar_embedding(texto_limpo)
            
            # Gera embeddings de cada chunk
            embeddings_chunks = llm_client.gerar_embeddings_para_chunks(chunks)
            
            resultado['embeddings_info'] = {
                'modelo': 'text-embedding-3-small',
                'dimensao': len(embedding_global),
                'num_embeddings': len(embeddings_chunks) + 1  # chunks + global
            }
        
        # Etapa 3: Sele√ß√£o de chunks relevantes
        with st.spinner("Selecionando trechos mais relevantes..."):
            chunks_selecionados = nlp_pipeline.selecionar_chunks_relevantes(
                chunks,
                embeddings_chunks,
                embedding_global,
                percentual_selecao=0.7
            )
            
            resultado['chunks_selecionados'] = chunks_selecionados
        
        # Etapa 4: Gera√ß√£o com LLM
        with st.spinner(f"Gerando {tipo_saida.lower()} com o4-mini..."):
            resposta_llm = llm_client.gerar_texto_o4_mini(
                texto_limpo,
                chunks_selecionados,
                tipo_saida,
                tamanho_resumo
            )
            
            if resposta_llm['sucesso']:
                resultado['texto_gerado'] = resposta_llm['texto_gerado']
                resultado['sucesso'] = True
                
                # Calcula estat√≠sticas do texto gerado
                resultado['estatisticas_saida'] = nlp_pipeline.calcular_estatisticas(
                    resposta_llm['texto_gerado']
                )
            else:
                resultado['erro'] = resposta_llm.get('erro', 'Erro desconhecido')
        
    except Exception as e:
        resultado['erro'] = f"Erro durante processamento: {str(e)}"
    
    return resultado




def main():
    """
    Fun√ß√£o principal da aplica√ß√£o Streamlit.
    """
    # Cabe√ßalho
    st.title("Vozes acess√≠veis")
    st.markdown("Ferramenta de processamento de linguagem natural para tornar textos mais acess√≠veis")
    
    # Sidebar - Configura√ß√µes
    with st.sidebar:
        st.header("Configura√ß√µes")
        
        # Tipo de sa√≠da
        tipo_saida = st.radio(
            "Tipo de sa√≠da:",
            options=["Resumo", "Versao simplificada"],
            help="Escolha entre gerar um resumo objetivo ou uma vers√£o simplificada do texto"
        )
        
        # Tamanho do resumo (apenas para resumos)
        tamanho_resumo = "Medio"
        if tipo_saida == "Resumo":
            tamanho_resumo = st.select_slider(
                "Tamanho do resumo:",
                options=["Curto", "Medio", "Longo"],
                value="Medio",
                help="Define o n√≠vel de detalhe do resumo gerado"
            )
        
        # Op√ß√£o de mostrar detalhes t√©cnicos
        mostrar_detalhes = st.checkbox(
            "Exibir detalhes do processamento de NLP",
            value=False,
            help="Mostra informa√ß√µes t√©cnicas sobre chunks, embeddings e sele√ß√£o"
        )
        
        st.divider()
        
        # Verifica√ß√£o de disponibilidade da API
        st.subheader("Status da API")
        status_api = llm_client.verificar_disponibilidade_api()
        
        if status_api['api_acessivel']:
            st.success("API OpenAI: Configurada")
        elif status_api['chave_configurada']:
            st.warning("API OpenAI: Chave configurada, mas n√£o testada")
        else:
            st.error("API OpenAI: N√£o configurada")
            st.caption(status_api['mensagem'])
    
    # √Årea principal
    st.header("Entrada de Texto")
    
    # Abas para diferentes formas de entrada
    aba_texto, aba_arquivo = st.tabs(["Colar texto", "Enviar arquivo"])
    
    texto_entrada = ""
    
    with aba_texto:
        texto_entrada = st.text_area(
            "Cole seu texto aqui:",
            height=300,
            placeholder="Digite ou cole o texto que deseja processar...",
            help="√Årea para entrada manual de texto"
        )
    
    with aba_arquivo:
        arquivo = st.file_uploader(
            "Ou envie um arquivo de texto ou PDF:",
            type=['txt', 'pdf'],
            help="Formatos suportados: .txt e .pdf"
        )
        
        if arquivo is not None:
            st.info(f"Arquivo carregado: {arquivo.name}")
            texto_extraido = extrair_texto_de_arquivo(arquivo)
            
            if texto_extraido:
                texto_entrada = texto_extraido
                st.success(f"Texto extra√≠do com sucesso ({len(texto_extraido)} caracteres)")
    
    # Mostra pr√©via do texto de entrada se houver
    if texto_entrada:
        with st.expander("Visualizar texto de entrada"):
            st.text_area("Texto que ser√° processado:", texto_entrada, height=150, disabled=True)
    
    # Bot√£o de processamento
    st.divider()
    
    col_botao1, col_botao2, col_botao3 = st.columns([1, 2, 1])
    
    with col_botao2:
        processar = st.button("Processar texto", use_container_width=True, type="primary")
    
    # Processamento
    if processar:
        if not texto_entrada or len(texto_entrada.strip()) < 50:
            st.error("Por favor, forne√ßa um texto com pelo menos 50 caracteres.")
        else:
            # Executa o processamento
            resultado = processar_texto(
                texto_entrada,
                tipo_saida,
                tamanho_resumo,
                mostrar_detalhes
            )
            
            if resultado['sucesso']:
                st.success("Processamento conclu√≠do com sucesso!")
                
                # Exibe resultado
                st.header("Resultado")
                
                # Caixa com o texto gerado
                st.subheader(f"{tipo_saida} Gerado")
                st.markdown(f"""
                <div style="background-color: #3D8737; padding: 1.5rem; 
                            border-radius: 10px; border-left: 5px solid #52b788; color: white;">
                {resultado['texto_gerado']}
                </div>
                """, unsafe_allow_html=True)
                
                # Estat√≠sticas comparativas
                st.subheader("Estat√≠sticas")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        "Palavras (entrada)",
                        resultado['estatisticas_entrada'].get('num_palavras', 0)
                    )
                
                with col2:
                    st.metric(
                        "Palavras (sa√≠da)",
                        resultado['estatisticas_saida'].get('num_palavras', 0)
                    )
                
                with col3:
                    st.metric(
                        "Frases (entrada)",
                        resultado['estatisticas_entrada'].get('num_frases', 0)
                    )
                
                with col4:
                    st.metric(
                        "Frases (sa√≠da)",
                        resultado['estatisticas_saida'].get('num_frases', 0)
                    )
                
                # Exibe detalhes t√©cnicos se solicitado
                if mostrar_detalhes:
                    st.divider()
                    exibir_detalhes_nlp(
                        resultado['chunks'],
                        resultado['chunks_selecionados'],
                        resultado['embeddings_info']
                    )
            
            else:
                st.error("Erro durante o processamento:")
                st.error(resultado['erro'])
                
                # Sugest√µes de solu√ß√£o
                st.info("""
                **Poss√≠veis solu√ß√µes:**
                - Verifique se a chave da API da OpenAI est√° configurada corretamente
                - Confirme que voc√™ tem cr√©ditos dispon√≠veis na sua conta OpenAI
                - Tente com um texto menor
                - Verifique sua conex√£o com a internet
                """)
    
    # Rodap√©
    st.divider()
    st.caption("Sistema de Resumo e Simplifica√ß√£o de Textos | Processamento com NLP e LLM")


if __name__ == "__main__":
    main()
